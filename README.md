# Welcome to my Github page!



## About me
My name is Yuxin Zhang. You can also call me Chloe! I'd like to thank you for taking time to visit my Github page. I am a first year graduate student in Statistical Science at University of California Santa Cruz. During this summer, I was very grateful that I had the chance to work at iFlytek, a key supplier of intelligent speech technologies, as a deep learning research intern. From this internship, I learned some fundemental concepts of deep learning especially in the field of optical character recognition. I was engaged in several projects such as using synthetic text dataset in natual scene to optimize recognition accuracy, robust reading on signboard and etc. This learning journey for the past few months has been nothing but truthfully challenging and fulfilling, and reaffirmed my passion in data science. Data Science is such a powerful tool to discover useful insights and translate data findings into actionable strategies. I'm excited to learn all aspects of data science especially the aspects of deep learning and to become a data scientist one day in the future. 
During my senior year of undergraduate study, I was involved in some data science projects. I'm happy to share my projects and the reports with you all! 

## My Projects

### Discovering Factors Leading to Popular Online News 

The past few decades have witnessed a fast expansion of digital journalism. People nowadays read, create, and share articles on the Internet. How can journalists optimize their contents to receive more views and shares from audiences? 

Our project aims to answer this question by exploring a dataset collected from Mashable news. The dataset consists of features and number of shares for each sample online news. We use simple linear regression models and logistic regression models to get robust estimation on featuresâ€™ effect on the popularity of online news. A careful model selection is performed using AIC as criteria. The result shows that online news with strong title, positive attitude, more visuals and simple format tend to be more popular, and the popularity differs by the channels and published day. 

To explore more: 



### Stats 141B : Data & Web Technologies for Data Analysis 

In this course, I've done data extraction through web scraping, api calls, and thorough exploratory data analysis involving visualization and statistical and machine learning techniques. 

To explore more:

[Exploration of SF data](https://github.com/Chloezhang96/github-page/blob/master/hw5.ipynb)
I analyzed a collection of data sets from the San Francisco Open Data Portal and Zillow. By asking few questions that I am interested in, I explored the dataset and found some interesting findings about SF crime rates and housing price. I used SQL to extract and read information. To better illustrate the findings, I applied maps from Geopandas by matching Zipcodes and matplotlib to compare the results. 

[Exploration of Aggie News](https://github.com/Chloezhang96/github-page/blob/master/hw6.ipynb)
In this project, I scraped text from the website [The California Aggie](https://theaggie.org/) and then analyzed the text. The goal of this project is to practice data extraction, visualization and natural language processing. 

    
### Stats 141A: Fundamentals of Statistical Data Science 

This course introduces computing for data analysis and visualization, and simulation, using a high-level language such as R. I learned computational reasoning, statistical modeling, reading tabular and non-standard data. 

[Handwritten Digit Recognition](https://github.com/Chloezhang96/Welcome/blob/master/Final%20Project%20--%20STA141A.pdf)
In the past, postal workers sorted mail by hand, which was tedious and expensive. Then to improve efficiency and save costs, USPS has switched to automated mail sorting, using statistical classifiers to identify the individual digits in the zip code on each piece of mail. In this project, I implemented the k-nearest neighbors algorithm for classifying handwritten digits in zip codes.
